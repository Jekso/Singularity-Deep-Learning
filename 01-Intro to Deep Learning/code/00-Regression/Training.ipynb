{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize': [7, 7]}, font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Address</th>\n",
       "      <th>Avatar</th>\n",
       "      <th>Avg. Session Length</th>\n",
       "      <th>Time on App</th>\n",
       "      <th>Time on Website</th>\n",
       "      <th>Length of Membership</th>\n",
       "      <th>Yearly Amount Spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mstephenson@fernandez.com</td>\n",
       "      <td>835 Frank Tunnel\\nWrightmouth, MI 82180-9605</td>\n",
       "      <td>Violet</td>\n",
       "      <td>34.497268</td>\n",
       "      <td>12.655651</td>\n",
       "      <td>39.577668</td>\n",
       "      <td>4.082621</td>\n",
       "      <td>587.951054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hduke@hotmail.com</td>\n",
       "      <td>4547 Archer Common\\nDiazchester, CA 06566-8576</td>\n",
       "      <td>DarkGreen</td>\n",
       "      <td>31.926272</td>\n",
       "      <td>11.109461</td>\n",
       "      <td>37.268959</td>\n",
       "      <td>2.664034</td>\n",
       "      <td>392.204933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pallen@yahoo.com</td>\n",
       "      <td>24645 Valerie Unions Suite 582\\nCobbborough, D...</td>\n",
       "      <td>Bisque</td>\n",
       "      <td>33.000915</td>\n",
       "      <td>11.330278</td>\n",
       "      <td>37.110597</td>\n",
       "      <td>4.104543</td>\n",
       "      <td>487.547505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>riverarebecca@gmail.com</td>\n",
       "      <td>1414 David Throughway\\nPort Jason, OH 22070-1220</td>\n",
       "      <td>SaddleBrown</td>\n",
       "      <td>34.305557</td>\n",
       "      <td>13.717514</td>\n",
       "      <td>36.721283</td>\n",
       "      <td>3.120179</td>\n",
       "      <td>581.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mstephens@davidson-herman.com</td>\n",
       "      <td>14023 Rodriguez Passage\\nPort Jacobville, PR 3...</td>\n",
       "      <td>MediumAquaMarine</td>\n",
       "      <td>33.330673</td>\n",
       "      <td>12.795189</td>\n",
       "      <td>37.536653</td>\n",
       "      <td>4.446308</td>\n",
       "      <td>599.406092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>lewisjessica@craig-evans.com</td>\n",
       "      <td>4483 Jones Motorway Suite 872\\nLake Jamiefurt,...</td>\n",
       "      <td>Tan</td>\n",
       "      <td>33.237660</td>\n",
       "      <td>13.566160</td>\n",
       "      <td>36.417985</td>\n",
       "      <td>3.746573</td>\n",
       "      <td>573.847438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>katrina56@gmail.com</td>\n",
       "      <td>172 Owen Divide Suite 497\\nWest Richard, CA 19320</td>\n",
       "      <td>PaleVioletRed</td>\n",
       "      <td>34.702529</td>\n",
       "      <td>11.695736</td>\n",
       "      <td>37.190268</td>\n",
       "      <td>3.576526</td>\n",
       "      <td>529.049004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dale88@hotmail.com</td>\n",
       "      <td>0787 Andrews Ranch Apt. 633\\nSouth Chadburgh, ...</td>\n",
       "      <td>Cornsilk</td>\n",
       "      <td>32.646777</td>\n",
       "      <td>11.499409</td>\n",
       "      <td>38.332576</td>\n",
       "      <td>4.958264</td>\n",
       "      <td>551.620145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>cwilson@hotmail.com</td>\n",
       "      <td>680 Jennifer Lodge Apt. 808\\nBrendachester, TX...</td>\n",
       "      <td>Teal</td>\n",
       "      <td>33.322501</td>\n",
       "      <td>12.391423</td>\n",
       "      <td>36.840086</td>\n",
       "      <td>2.336485</td>\n",
       "      <td>456.469510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>hannahwilson@davidson.com</td>\n",
       "      <td>49791 Rachel Heights Apt. 898\\nEast Drewboroug...</td>\n",
       "      <td>DarkMagenta</td>\n",
       "      <td>33.715981</td>\n",
       "      <td>12.418808</td>\n",
       "      <td>35.771016</td>\n",
       "      <td>2.735160</td>\n",
       "      <td>497.778642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Email  \\\n",
       "0        mstephenson@fernandez.com   \n",
       "1                hduke@hotmail.com   \n",
       "2                 pallen@yahoo.com   \n",
       "3          riverarebecca@gmail.com   \n",
       "4    mstephens@davidson-herman.com   \n",
       "..                             ...   \n",
       "495   lewisjessica@craig-evans.com   \n",
       "496            katrina56@gmail.com   \n",
       "497             dale88@hotmail.com   \n",
       "498            cwilson@hotmail.com   \n",
       "499      hannahwilson@davidson.com   \n",
       "\n",
       "                                               Address            Avatar  \\\n",
       "0         835 Frank Tunnel\\nWrightmouth, MI 82180-9605            Violet   \n",
       "1       4547 Archer Common\\nDiazchester, CA 06566-8576         DarkGreen   \n",
       "2    24645 Valerie Unions Suite 582\\nCobbborough, D...            Bisque   \n",
       "3     1414 David Throughway\\nPort Jason, OH 22070-1220       SaddleBrown   \n",
       "4    14023 Rodriguez Passage\\nPort Jacobville, PR 3...  MediumAquaMarine   \n",
       "..                                                 ...               ...   \n",
       "495  4483 Jones Motorway Suite 872\\nLake Jamiefurt,...               Tan   \n",
       "496  172 Owen Divide Suite 497\\nWest Richard, CA 19320     PaleVioletRed   \n",
       "497  0787 Andrews Ranch Apt. 633\\nSouth Chadburgh, ...          Cornsilk   \n",
       "498  680 Jennifer Lodge Apt. 808\\nBrendachester, TX...              Teal   \n",
       "499  49791 Rachel Heights Apt. 898\\nEast Drewboroug...       DarkMagenta   \n",
       "\n",
       "     Avg. Session Length  Time on App  Time on Website  Length of Membership  \\\n",
       "0              34.497268    12.655651        39.577668              4.082621   \n",
       "1              31.926272    11.109461        37.268959              2.664034   \n",
       "2              33.000915    11.330278        37.110597              4.104543   \n",
       "3              34.305557    13.717514        36.721283              3.120179   \n",
       "4              33.330673    12.795189        37.536653              4.446308   \n",
       "..                   ...          ...              ...                   ...   \n",
       "495            33.237660    13.566160        36.417985              3.746573   \n",
       "496            34.702529    11.695736        37.190268              3.576526   \n",
       "497            32.646777    11.499409        38.332576              4.958264   \n",
       "498            33.322501    12.391423        36.840086              2.336485   \n",
       "499            33.715981    12.418808        35.771016              2.735160   \n",
       "\n",
       "     Yearly Amount Spent  \n",
       "0             587.951054  \n",
       "1             392.204933  \n",
       "2             487.547505  \n",
       "3             581.852344  \n",
       "4             599.406092  \n",
       "..                   ...  \n",
       "495           573.847438  \n",
       "496           529.049004  \n",
       "497           551.620145  \n",
       "498           456.469510  \n",
       "499           497.778642  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Ecommerce Customers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Email                 500 non-null    object \n",
      " 1   Address               500 non-null    object \n",
      " 2   Avatar                500 non-null    object \n",
      " 3   Avg. Session Length   500 non-null    float64\n",
      " 4   Time on App           500 non-null    float64\n",
      " 5   Time on Website       500 non-null    float64\n",
      " 6   Length of Membership  500 non-null    float64\n",
      " 7   Yearly Amount Spent   500 non-null    float64\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Session Length</th>\n",
       "      <th>Time on App</th>\n",
       "      <th>Time on Website</th>\n",
       "      <th>Length of Membership</th>\n",
       "      <th>Yearly Amount Spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.053194</td>\n",
       "      <td>12.052488</td>\n",
       "      <td>37.060445</td>\n",
       "      <td>3.533462</td>\n",
       "      <td>499.314038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.992563</td>\n",
       "      <td>0.994216</td>\n",
       "      <td>1.010489</td>\n",
       "      <td>0.999278</td>\n",
       "      <td>79.314782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.532429</td>\n",
       "      <td>8.508152</td>\n",
       "      <td>33.913847</td>\n",
       "      <td>0.269901</td>\n",
       "      <td>256.670582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.341822</td>\n",
       "      <td>11.388153</td>\n",
       "      <td>36.349257</td>\n",
       "      <td>2.930450</td>\n",
       "      <td>445.038277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.082008</td>\n",
       "      <td>11.983231</td>\n",
       "      <td>37.069367</td>\n",
       "      <td>3.533975</td>\n",
       "      <td>498.887875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.711985</td>\n",
       "      <td>12.753850</td>\n",
       "      <td>37.716432</td>\n",
       "      <td>4.126502</td>\n",
       "      <td>549.313828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.139662</td>\n",
       "      <td>15.126994</td>\n",
       "      <td>40.005182</td>\n",
       "      <td>6.922689</td>\n",
       "      <td>765.518462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Avg. Session Length  Time on App  Time on Website  \\\n",
       "count           500.000000   500.000000       500.000000   \n",
       "mean             33.053194    12.052488        37.060445   \n",
       "std               0.992563     0.994216         1.010489   \n",
       "min              29.532429     8.508152        33.913847   \n",
       "25%              32.341822    11.388153        36.349257   \n",
       "50%              33.082008    11.983231        37.069367   \n",
       "75%              33.711985    12.753850        37.716432   \n",
       "max              36.139662    15.126994        40.005182   \n",
       "\n",
       "       Length of Membership  Yearly Amount Spent  \n",
       "count            500.000000           500.000000  \n",
       "mean               3.533462           499.314038  \n",
       "std                0.999278            79.314782  \n",
       "min                0.269901           256.670582  \n",
       "25%                2.930450           445.038277  \n",
       "50%                3.533975           498.887875  \n",
       "75%                4.126502           549.313828  \n",
       "max                6.922689           765.518462  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']]\n",
    "y = df['Yearly Amount Spent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2048, input_shape=[x.shape[1]], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2048)              10240     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,945,985\n",
      "Trainable params: 3,945,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                         patience = 200,\n",
    "                         verbose = 1,\n",
    "                         factor = 0.75,\n",
    "                         min_lr = 1e-10)\n",
    "\n",
    "mcp = ModelCheckpoint('model.h5')\n",
    "\n",
    "es = EarlyStopping(verbose=1, patience=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360 samples, validate on 40 samples\n",
      "Epoch 1/500\n",
      "360/360 [==============================] - 1s 3ms/sample - loss: 248909.7521 - val_loss: 179555.6250\n",
      "Epoch 2/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 95025.3411 - val_loss: 44827.7500\n",
      "Epoch 3/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 42395.7584 - val_loss: 52289.2617\n",
      "Epoch 4/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 38776.1309 - val_loss: 41165.9922\n",
      "Epoch 5/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 29596.4299 - val_loss: 33124.3242\n",
      "Epoch 6/500\n",
      "360/360 [==============================] - 2s 5ms/sample - loss: 23490.9406 - val_loss: 22555.3008\n",
      "Epoch 7/500\n",
      "360/360 [==============================] - 0s 403us/sample - loss: 19916.5397 - val_loss: 20967.3867\n",
      "Epoch 8/500\n",
      "360/360 [==============================] - 0s 394us/sample - loss: 17239.9390 - val_loss: 15861.8340\n",
      "Epoch 9/500\n",
      "360/360 [==============================] - 0s 403us/sample - loss: 14506.1114 - val_loss: 15039.0059\n",
      "Epoch 10/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 12807.7702 - val_loss: 12381.8555\n",
      "Epoch 11/500\n",
      "360/360 [==============================] - 0s 365us/sample - loss: 11587.4900 - val_loss: 10906.1152\n",
      "Epoch 12/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 9704.9744 - val_loss: 8819.3496\n",
      "Epoch 13/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 8277.5614 - val_loss: 7103.3530\n",
      "Epoch 14/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 7313.5832 - val_loss: 6166.7476\n",
      "Epoch 15/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 5851.4116 - val_loss: 5023.6855\n",
      "Epoch 16/500\n",
      "360/360 [==============================] - 0s 431us/sample - loss: 5255.0354 - val_loss: 4113.4634\n",
      "Epoch 17/500\n",
      "360/360 [==============================] - 0s 428us/sample - loss: 4212.8105 - val_loss: 3434.2031\n",
      "Epoch 18/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 3469.6464 - val_loss: 2503.2537\n",
      "Epoch 19/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 3230.0371 - val_loss: 2019.5769\n",
      "Epoch 20/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 2301.3307 - val_loss: 2030.4333\n",
      "Epoch 21/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 2295.3326 - val_loss: 1335.2653\n",
      "Epoch 22/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 2058.0927 - val_loss: 1159.8967\n",
      "Epoch 23/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 1742.0153 - val_loss: 900.5978\n",
      "Epoch 24/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 1385.0120 - val_loss: 589.2020\n",
      "Epoch 25/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 1306.6378 - val_loss: 737.8702\n",
      "Epoch 26/500\n",
      "360/360 [==============================] - 0s 533us/sample - loss: 1067.6536 - val_loss: 466.8919\n",
      "Epoch 27/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 986.4924 - val_loss: 326.5611\n",
      "Epoch 28/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 1073.8768 - val_loss: 242.0374\n",
      "Epoch 29/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 861.7306 - val_loss: 336.6480\n",
      "Epoch 30/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 776.5779 - val_loss: 250.7294\n",
      "Epoch 31/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 847.1233 - val_loss: 257.2665\n",
      "Epoch 32/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 890.8845 - val_loss: 160.6510\n",
      "Epoch 33/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 953.6406 - val_loss: 264.7622\n",
      "Epoch 34/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 883.3261 - val_loss: 210.0581\n",
      "Epoch 35/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 746.0697 - val_loss: 186.3970\n",
      "Epoch 36/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 716.2695 - val_loss: 136.4911\n",
      "Epoch 37/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 774.1421 - val_loss: 229.7561\n",
      "Epoch 38/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 837.7263 - val_loss: 152.4981\n",
      "Epoch 39/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 867.7625 - val_loss: 150.0426\n",
      "Epoch 40/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 840.3458 - val_loss: 195.1372\n",
      "Epoch 41/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 794.6561 - val_loss: 161.3808\n",
      "Epoch 42/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 714.4126 - val_loss: 328.1563\n",
      "Epoch 43/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 884.3511 - val_loss: 290.2035\n",
      "Epoch 44/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 702.9609 - val_loss: 173.7248\n",
      "Epoch 45/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 740.1098 - val_loss: 125.7281\n",
      "Epoch 46/500\n",
      "360/360 [==============================] - 0s 614us/sample - loss: 627.7139 - val_loss: 134.4343\n",
      "Epoch 47/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 868.4748 - val_loss: 234.3356\n",
      "Epoch 48/500\n",
      "360/360 [==============================] - 0s 406us/sample - loss: 701.0900 - val_loss: 155.7760\n",
      "Epoch 49/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 684.0276 - val_loss: 144.8286\n",
      "Epoch 50/500\n",
      "360/360 [==============================] - 0s 392us/sample - loss: 605.7176 - val_loss: 200.0755\n",
      "Epoch 51/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 770.3870 - val_loss: 250.3803\n",
      "Epoch 52/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 776.2849 - val_loss: 280.7008\n",
      "Epoch 53/500\n",
      "360/360 [==============================] - 0s 385us/sample - loss: 767.0719 - val_loss: 130.0196\n",
      "Epoch 54/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 681.6598 - val_loss: 197.1778\n",
      "Epoch 55/500\n",
      "360/360 [==============================] - 0s 723us/sample - loss: 772.6248 - val_loss: 533.2992\n",
      "Epoch 56/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 842.0962 - val_loss: 372.8698\n",
      "Epoch 57/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 799.0893 - val_loss: 347.4129\n",
      "Epoch 58/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 673.5546 - val_loss: 123.0194\n",
      "Epoch 59/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 644.4404 - val_loss: 130.4037\n",
      "Epoch 60/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 590.9039 - val_loss: 193.5525\n",
      "Epoch 61/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 738.7091 - val_loss: 132.5061\n",
      "Epoch 62/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 689.1891 - val_loss: 159.2180\n",
      "Epoch 63/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 779.2992 - val_loss: 154.1339\n",
      "Epoch 64/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 933.4912 - val_loss: 133.1657\n",
      "Epoch 65/500\n",
      "360/360 [==============================] - 0s 486us/sample - loss: 719.3610 - val_loss: 229.4252\n",
      "Epoch 66/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 717.8571 - val_loss: 122.0810\n",
      "Epoch 67/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 856.9705 - val_loss: 162.1330\n",
      "Epoch 68/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 813.1692 - val_loss: 203.5477\n",
      "Epoch 69/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 674.6183 - val_loss: 171.1527\n",
      "Epoch 70/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 787.7755 - val_loss: 314.9561\n",
      "Epoch 71/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 762.0177 - val_loss: 236.9231\n",
      "Epoch 72/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 667.6385 - val_loss: 120.3373\n",
      "Epoch 73/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 742.0855 - val_loss: 327.1129\n",
      "Epoch 74/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 713.1524 - val_loss: 163.1317\n",
      "Epoch 75/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 824.2367 - val_loss: 480.3398\n",
      "Epoch 76/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 744.4816 - val_loss: 345.3007\n",
      "Epoch 77/500\n",
      "360/360 [==============================] - 0s 355us/sample - loss: 778.6692 - val_loss: 222.0407\n",
      "Epoch 78/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 833.2312 - val_loss: 134.1990\n",
      "Epoch 79/500\n",
      "360/360 [==============================] - 0s 368us/sample - loss: 741.0356 - val_loss: 114.0142\n",
      "Epoch 80/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 752.4846 - val_loss: 223.0448\n",
      "Epoch 81/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 710.3167 - val_loss: 227.3397\n",
      "Epoch 82/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 656.6310 - val_loss: 114.4131\n",
      "Epoch 83/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 715.1289 - val_loss: 237.1561\n",
      "Epoch 84/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 698.6837 - val_loss: 127.4273\n",
      "Epoch 85/500\n",
      "360/360 [==============================] - 0s 614us/sample - loss: 711.9731 - val_loss: 158.7540\n",
      "Epoch 86/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 706.8634 - val_loss: 197.2276\n",
      "Epoch 87/500\n",
      "360/360 [==============================] - 0s 550us/sample - loss: 600.1610 - val_loss: 124.9391\n",
      "Epoch 88/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 746.8854 - val_loss: 206.3542\n",
      "Epoch 89/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 640.4625 - val_loss: 281.5875\n",
      "Epoch 90/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 739.0483 - val_loss: 127.3685\n",
      "Epoch 91/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 629.1578 - val_loss: 120.8017\n",
      "Epoch 92/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 662.5506 - val_loss: 151.3931\n",
      "Epoch 93/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 568.4301 - val_loss: 122.1028\n",
      "Epoch 94/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 543.6102 - val_loss: 139.3748\n",
      "Epoch 95/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 623.8247 - val_loss: 223.7555\n",
      "Epoch 96/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 614.9752 - val_loss: 158.5569\n",
      "Epoch 97/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 608.4887 - val_loss: 133.8940\n",
      "Epoch 98/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 707.1418 - val_loss: 484.4899\n",
      "Epoch 99/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 833.8204 - val_loss: 206.9838\n",
      "Epoch 100/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 721.7271 - val_loss: 255.5309\n",
      "Epoch 101/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 801.2108 - val_loss: 176.9453\n",
      "Epoch 102/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 1021.9994 - val_loss: 363.3125\n",
      "Epoch 103/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 979.0212 - val_loss: 1175.4941\n",
      "Epoch 104/500\n",
      "360/360 [==============================] - 0s 653us/sample - loss: 1047.1182 - val_loss: 292.7153\n",
      "Epoch 105/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 1072.7350 - val_loss: 243.7685\n",
      "Epoch 106/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 772.4224 - val_loss: 234.7101\n",
      "Epoch 107/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 740.6546 - val_loss: 258.2677\n",
      "Epoch 108/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 539.5703 - val_loss: 169.1997\n",
      "Epoch 109/500\n",
      "360/360 [==============================] - 0s 413us/sample - loss: 773.5749 - val_loss: 116.2307\n",
      "Epoch 110/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 775.6092 - val_loss: 247.6983\n",
      "Epoch 111/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 757.2318 - val_loss: 235.0896\n",
      "Epoch 112/500\n",
      "360/360 [==============================] - 0s 365us/sample - loss: 633.5058 - val_loss: 120.5721\n",
      "Epoch 113/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 674.5674 - val_loss: 189.5526\n",
      "Epoch 114/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 659.4680 - val_loss: 211.4039\n",
      "Epoch 115/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 694.8895 - val_loss: 219.0938\n",
      "Epoch 116/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 651.0156 - val_loss: 125.4751\n",
      "Epoch 117/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 665.1400 - val_loss: 136.2448\n",
      "Epoch 118/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 773.0199 - val_loss: 276.8125\n",
      "Epoch 119/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 864.1016 - val_loss: 606.7318\n",
      "Epoch 120/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 831.8826 - val_loss: 467.2273\n",
      "Epoch 121/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 1021.2658 - val_loss: 436.5174\n",
      "Epoch 122/500\n",
      "360/360 [==============================] - 0s 392us/sample - loss: 831.4264 - val_loss: 302.1578\n",
      "Epoch 123/500\n",
      "360/360 [==============================] - 0s 419us/sample - loss: 615.6854 - val_loss: 168.9061\n",
      "Epoch 124/500\n",
      "360/360 [==============================] - 0s 725us/sample - loss: 687.8559 - val_loss: 276.2602\n",
      "Epoch 125/500\n",
      "360/360 [==============================] - 0s 408us/sample - loss: 694.7232 - val_loss: 158.6929\n",
      "Epoch 126/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 627.5071 - val_loss: 413.9129\n",
      "Epoch 127/500\n",
      "360/360 [==============================] - 0s 394us/sample - loss: 845.0683 - val_loss: 274.7941\n",
      "Epoch 128/500\n",
      "360/360 [==============================] - 0s 464us/sample - loss: 788.0946 - val_loss: 521.0262\n",
      "Epoch 129/500\n",
      "360/360 [==============================] - 0s 458us/sample - loss: 750.2471 - val_loss: 226.6608\n",
      "Epoch 130/500\n",
      "360/360 [==============================] - 0s 403us/sample - loss: 778.0934 - val_loss: 347.3290\n",
      "Epoch 131/500\n",
      "360/360 [==============================] - 0s 404us/sample - loss: 783.7783 - val_loss: 224.1153\n",
      "Epoch 132/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 701.0537 - val_loss: 141.0985\n",
      "Epoch 133/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 793.7578 - val_loss: 335.4018\n",
      "Epoch 134/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 605.2915 - val_loss: 121.3964\n",
      "Epoch 135/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 635.2999 - val_loss: 170.1817\n",
      "Epoch 136/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 570.8093 - val_loss: 123.0072\n",
      "Epoch 137/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 526.2940 - val_loss: 154.8507\n",
      "Epoch 138/500\n",
      "360/360 [==============================] - 0s 394us/sample - loss: 617.5540 - val_loss: 126.3537\n",
      "Epoch 139/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 812.6077 - val_loss: 133.6633\n",
      "Epoch 140/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 619.7774 - val_loss: 282.9998\n",
      "Epoch 141/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 582.7041 - val_loss: 130.1121\n",
      "Epoch 142/500\n",
      "360/360 [==============================] - 0s 597us/sample - loss: 640.4572 - val_loss: 292.3435\n",
      "Epoch 143/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 735.0676 - val_loss: 295.4395\n",
      "Epoch 144/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 607.8980 - val_loss: 138.9204\n",
      "Epoch 145/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 754.8131 - val_loss: 197.5762\n",
      "Epoch 146/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 819.5840 - val_loss: 297.3664\n",
      "Epoch 147/500\n",
      "360/360 [==============================] - 0s 363us/sample - loss: 1217.3454 - val_loss: 1671.7418\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 364us/sample - loss: 1708.1617 - val_loss: 962.3099\n",
      "Epoch 149/500\n",
      "360/360 [==============================] - 0s 363us/sample - loss: 1232.4079 - val_loss: 925.6263\n",
      "Epoch 150/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 1265.2557 - val_loss: 561.0549\n",
      "Epoch 151/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 962.5350 - val_loss: 198.6480\n",
      "Epoch 152/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 631.2478 - val_loss: 197.5141\n",
      "Epoch 153/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 645.0124 - val_loss: 405.3012\n",
      "Epoch 154/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 806.2325 - val_loss: 149.7602\n",
      "Epoch 155/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 607.7766 - val_loss: 194.4920\n",
      "Epoch 156/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 747.8044 - val_loss: 159.3655\n",
      "Epoch 157/500\n",
      "360/360 [==============================] - 0s 397us/sample - loss: 641.7238 - val_loss: 170.4043\n",
      "Epoch 158/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 655.1190 - val_loss: 147.7390\n",
      "Epoch 159/500\n",
      "360/360 [==============================] - 0s 406us/sample - loss: 694.7576 - val_loss: 322.0508\n",
      "Epoch 160/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 634.0077 - val_loss: 213.7725\n",
      "Epoch 161/500\n",
      "360/360 [==============================] - 0s 413us/sample - loss: 677.3728 - val_loss: 155.1867\n",
      "Epoch 162/500\n",
      "360/360 [==============================] - 0s 765us/sample - loss: 959.8122 - val_loss: 305.9906\n",
      "Epoch 163/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 786.4306 - val_loss: 221.7755\n",
      "Epoch 164/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 693.8022 - val_loss: 213.5965\n",
      "Epoch 165/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 713.7397 - val_loss: 133.5010\n",
      "Epoch 166/500\n",
      "360/360 [==============================] - 0s 403us/sample - loss: 671.5701 - val_loss: 142.7101\n",
      "Epoch 167/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 713.7682 - val_loss: 246.4319\n",
      "Epoch 168/500\n",
      "360/360 [==============================] - 0s 406us/sample - loss: 666.4464 - val_loss: 280.3141\n",
      "Epoch 169/500\n",
      "360/360 [==============================] - 0s 370us/sample - loss: 777.0498 - val_loss: 351.8638\n",
      "Epoch 170/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 779.6980 - val_loss: 293.7132\n",
      "Epoch 171/500\n",
      "360/360 [==============================] - 0s 475us/sample - loss: 700.5280 - val_loss: 138.7623\n",
      "Epoch 172/500\n",
      "360/360 [==============================] - 0s 414us/sample - loss: 708.2448 - val_loss: 704.7159\n",
      "Epoch 173/500\n",
      "360/360 [==============================] - 0s 397us/sample - loss: 1006.2594 - val_loss: 479.2143\n",
      "Epoch 174/500\n",
      "360/360 [==============================] - 0s 400us/sample - loss: 859.2764 - val_loss: 486.2629\n",
      "Epoch 175/500\n",
      "360/360 [==============================] - 0s 400us/sample - loss: 787.4352 - val_loss: 339.8891\n",
      "Epoch 176/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 646.8663 - val_loss: 157.6221\n",
      "Epoch 177/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 634.1387 - val_loss: 356.1636\n",
      "Epoch 178/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 769.4550 - val_loss: 580.5470\n",
      "Epoch 179/500\n",
      "360/360 [==============================] - 0s 360us/sample - loss: 892.9534 - val_loss: 770.4201\n",
      "Epoch 180/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 1055.3665 - val_loss: 445.1483\n",
      "Epoch 181/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 1214.9187 - val_loss: 828.4012\n",
      "Epoch 182/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 1022.4155 - val_loss: 210.0981\n",
      "Epoch 183/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 765.4664 - val_loss: 248.1860\n",
      "Epoch 184/500\n",
      "360/360 [==============================] - 0s 350us/sample - loss: 587.8080 - val_loss: 136.8956\n",
      "Epoch 185/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 547.6547 - val_loss: 210.1419\n",
      "Epoch 186/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 608.2595 - val_loss: 126.4581\n",
      "Epoch 187/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 634.2648 - val_loss: 178.2817\n",
      "Epoch 188/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 609.9193 - val_loss: 119.1777\n",
      "Epoch 189/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 553.5266 - val_loss: 149.7375\n",
      "Epoch 190/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 624.6024 - val_loss: 125.1707\n",
      "Epoch 191/500\n",
      "360/360 [==============================] - 0s 414us/sample - loss: 549.8653 - val_loss: 146.0993\n",
      "Epoch 192/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 580.6053 - val_loss: 363.1305\n",
      "Epoch 193/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 736.9868 - val_loss: 446.0375\n",
      "Epoch 194/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 830.4182 - val_loss: 252.1254\n",
      "Epoch 195/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 696.2582 - val_loss: 266.6548\n",
      "Epoch 196/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 677.9436 - val_loss: 182.4406\n",
      "Epoch 197/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 653.4885 - val_loss: 205.3119\n",
      "Epoch 198/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 605.9347 - val_loss: 228.8287\n",
      "Epoch 199/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 576.8461 - val_loss: 167.7783\n",
      "Epoch 200/500\n",
      "360/360 [==============================] - 0s 408us/sample - loss: 581.2102 - val_loss: 266.5243\n",
      "Epoch 201/500\n",
      "360/360 [==============================] - 0s 828us/sample - loss: 595.7244 - val_loss: 217.4214\n",
      "Epoch 202/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 710.9069 - val_loss: 194.5006\n",
      "Epoch 203/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 791.9978 - val_loss: 1915.6033\n",
      "Epoch 204/500\n",
      "360/360 [==============================] - 0s 403us/sample - loss: 1339.7288 - val_loss: 226.1680\n",
      "Epoch 205/500\n",
      "360/360 [==============================] - 0s 414us/sample - loss: 1012.5224 - val_loss: 532.1709\n",
      "Epoch 206/500\n",
      "360/360 [==============================] - 0s 380us/sample - loss: 1089.3938 - val_loss: 752.4357\n",
      "Epoch 207/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 922.9579 - val_loss: 562.9772\n",
      "Epoch 208/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 937.2135 - val_loss: 517.9476\n",
      "Epoch 209/500\n",
      "360/360 [==============================] - 0s 377us/sample - loss: 1130.7414 - val_loss: 178.6471\n",
      "Epoch 210/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 793.4963 - val_loss: 288.8400\n",
      "Epoch 211/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 634.3777 - val_loss: 209.2013\n",
      "Epoch 212/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 657.7982 - val_loss: 185.1280\n",
      "Epoch 213/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 736.3050 - val_loss: 146.2112\n",
      "Epoch 214/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 668.7730 - val_loss: 408.3354\n",
      "Epoch 215/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 739.3731 - val_loss: 148.5028\n",
      "Epoch 216/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 599.6373 - val_loss: 134.1578\n",
      "Epoch 217/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 584.7459 - val_loss: 227.5562\n",
      "Epoch 218/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 737.1222 - val_loss: 488.8214\n",
      "Epoch 219/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 742.4494 - val_loss: 723.6906\n",
      "Epoch 220/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 841.7759 - val_loss: 137.1497\n",
      "Epoch 221/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 724.8805 - val_loss: 799.4976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 853.2729 - val_loss: 747.2734\n",
      "Epoch 223/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 1101.9462 - val_loss: 1852.4365\n",
      "Epoch 224/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 1437.6157 - val_loss: 448.3595\n",
      "Epoch 225/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 707.7717 - val_loss: 365.5563\n",
      "Epoch 226/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 742.4380 - val_loss: 198.3178\n",
      "Epoch 227/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 700.8872 - val_loss: 207.0382\n",
      "Epoch 228/500\n",
      "360/360 [==============================] - 0s 392us/sample - loss: 611.2343 - val_loss: 528.1559\n",
      "Epoch 229/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 666.4642 - val_loss: 132.7942\n",
      "Epoch 230/500\n",
      "360/360 [==============================] - 0s 745us/sample - loss: 710.8134 - val_loss: 150.9237\n",
      "Epoch 231/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 608.7062 - val_loss: 223.2857\n",
      "Epoch 232/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 655.6144 - val_loss: 134.7923\n",
      "Epoch 233/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 615.9008 - val_loss: 263.4306\n",
      "Epoch 234/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 723.3463 - val_loss: 519.8950\n",
      "Epoch 235/500\n",
      "360/360 [==============================] - 0s 371us/sample - loss: 785.8787 - val_loss: 240.5615\n",
      "Epoch 236/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 616.1023 - val_loss: 221.3900\n",
      "Epoch 237/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 495.7334 - val_loss: 137.6236\n",
      "Epoch 238/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 680.1380 - val_loss: 384.6860\n",
      "Epoch 239/500\n",
      "360/360 [==============================] - 0s 529us/sample - loss: 644.4708 - val_loss: 137.6318\n",
      "Epoch 240/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 745.5734 - val_loss: 170.9495\n",
      "Epoch 241/500\n",
      "360/360 [==============================] - 0s 606us/sample - loss: 816.8918 - val_loss: 190.0175\n",
      "Epoch 242/500\n",
      "360/360 [==============================] - 0s 405us/sample - loss: 717.6538 - val_loss: 462.0017\n",
      "Epoch 243/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 771.2584 - val_loss: 172.7075\n",
      "Epoch 244/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 627.5272 - val_loss: 200.0715\n",
      "Epoch 245/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 672.3539 - val_loss: 300.7173\n",
      "Epoch 246/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 667.9006 - val_loss: 154.5955\n",
      "Epoch 247/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 637.8815 - val_loss: 211.8716\n",
      "Epoch 248/500\n",
      "360/360 [==============================] - 0s 455us/sample - loss: 709.4841 - val_loss: 177.2455\n",
      "Epoch 249/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 680.8179 - val_loss: 222.4456\n",
      "Epoch 250/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 594.7875 - val_loss: 183.2853\n",
      "Epoch 251/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 653.1047 - val_loss: 142.8785\n",
      "Epoch 252/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 737.9956 - val_loss: 494.6942\n",
      "Epoch 253/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 672.0804 - val_loss: 130.6092\n",
      "Epoch 254/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 591.1055 - val_loss: 126.2794\n",
      "Epoch 255/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 537.5142 - val_loss: 148.3283\n",
      "Epoch 256/500\n",
      "360/360 [==============================] - 0s 355us/sample - loss: 536.1841 - val_loss: 166.8107\n",
      "Epoch 257/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 561.1826 - val_loss: 167.9772\n",
      "Epoch 258/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 653.1380 - val_loss: 381.5148\n",
      "Epoch 259/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 844.9694 - val_loss: 307.2782\n",
      "Epoch 260/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 742.0462 - val_loss: 580.0307\n",
      "Epoch 261/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 782.6404 - val_loss: 271.0068\n",
      "Epoch 262/500\n",
      "360/360 [==============================] - 0s 403us/sample - loss: 708.8211 - val_loss: 124.7683\n",
      "Epoch 263/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 675.9349 - val_loss: 411.6873\n",
      "Epoch 264/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 719.0649 - val_loss: 482.8883\n",
      "Epoch 265/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 967.2541 - val_loss: 143.0427\n",
      "Epoch 266/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 866.3225 - val_loss: 272.5953\n",
      "Epoch 267/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 598.5498 - val_loss: 166.7198\n",
      "Epoch 268/500\n",
      "360/360 [==============================] - 0s 596us/sample - loss: 761.9023 - val_loss: 388.6000\n",
      "Epoch 269/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 690.3554 - val_loss: 174.6179\n",
      "Epoch 270/500\n",
      "360/360 [==============================] - 0s 392us/sample - loss: 729.8509 - val_loss: 331.0887\n",
      "Epoch 271/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 710.0052 - val_loss: 260.8371\n",
      "Epoch 272/500\n",
      "360/360 [==============================] - 0s 394us/sample - loss: 650.4973 - val_loss: 150.0750\n",
      "Epoch 273/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 1213.9015 - val_loss: 156.4422\n",
      "Epoch 274/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 872.8941 - val_loss: 253.3010\n",
      "Epoch 275/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 613.0120 - val_loss: 609.8765\n",
      "Epoch 276/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 586.4601 - val_loss: 217.4288\n",
      "Epoch 277/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 692.7517 - val_loss: 149.4331\n",
      "Epoch 278/500\n",
      "360/360 [==============================] - 0s 796us/sample - loss: 716.8599 - val_loss: 830.0477\n",
      "Epoch 279/500\n",
      " 64/360 [====>.........................] - ETA: 0s - loss: 1204.6014\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 813.6011 - val_loss: 657.0880\n",
      "Epoch 280/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 907.8001 - val_loss: 367.5667\n",
      "Epoch 281/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 1059.5934 - val_loss: 330.8602\n",
      "Epoch 282/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 1032.3435 - val_loss: 810.4014\n",
      "Epoch 283/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 879.6995 - val_loss: 189.8475\n",
      "Epoch 284/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 532.0574 - val_loss: 149.2249\n",
      "Epoch 285/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 522.0740 - val_loss: 128.6737\n",
      "Epoch 286/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 515.1140 - val_loss: 195.2241\n",
      "Epoch 287/500\n",
      "360/360 [==============================] - 0s 637us/sample - loss: 575.3648 - val_loss: 162.2413\n",
      "Epoch 288/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 617.6918 - val_loss: 141.5804\n",
      "Epoch 289/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 594.0513 - val_loss: 380.9637\n",
      "Epoch 290/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 581.2769 - val_loss: 200.3884\n",
      "Epoch 291/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 668.1958 - val_loss: 261.9668\n",
      "Epoch 292/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 724.0163 - val_loss: 440.0123\n",
      "Epoch 293/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 889.3024 - val_loss: 536.5580\n",
      "Epoch 294/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 712.2277 - val_loss: 145.5394\n",
      "Epoch 295/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 654.1081 - val_loss: 238.7746\n",
      "Epoch 296/500\n",
      "360/360 [==============================] - 0s 431us/sample - loss: 616.5403 - val_loss: 156.0188\n",
      "Epoch 297/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 607.9678 - val_loss: 141.2538\n",
      "Epoch 298/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 595.5308 - val_loss: 359.6616\n",
      "Epoch 299/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 777.9044 - val_loss: 197.4756\n",
      "Epoch 300/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 929.7315 - val_loss: 225.9068\n",
      "Epoch 301/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 681.6603 - val_loss: 295.0434\n",
      "Epoch 302/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 607.4165 - val_loss: 212.8601\n",
      "Epoch 303/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 565.9647 - val_loss: 147.5705\n",
      "Epoch 304/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 570.3369 - val_loss: 143.0568\n",
      "Epoch 305/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 519.1666 - val_loss: 216.7234\n",
      "Epoch 306/500\n",
      "360/360 [==============================] - 0s 659us/sample - loss: 557.7711 - val_loss: 181.3559\n",
      "Epoch 307/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 676.9051 - val_loss: 131.7250\n",
      "Epoch 308/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 599.3051 - val_loss: 162.8088\n",
      "Epoch 309/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 555.1088 - val_loss: 130.3288\n",
      "Epoch 310/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 548.0156 - val_loss: 925.6569\n",
      "Epoch 311/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 1035.7249 - val_loss: 237.9514\n",
      "Epoch 312/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 804.8239 - val_loss: 482.9759\n",
      "Epoch 313/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 705.9067 - val_loss: 437.2797\n",
      "Epoch 314/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 725.9424 - val_loss: 522.2343\n",
      "Epoch 315/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 720.7653 - val_loss: 171.4780\n",
      "Epoch 316/500\n",
      "360/360 [==============================] - 0s 506us/sample - loss: 714.5968 - val_loss: 130.2544\n",
      "Epoch 317/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 718.9990 - val_loss: 490.8394\n",
      "Epoch 318/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 754.1164 - val_loss: 214.7319\n",
      "Epoch 319/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 616.7926 - val_loss: 134.7378\n",
      "Epoch 320/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 601.3231 - val_loss: 269.0821\n",
      "Epoch 321/500\n",
      "360/360 [==============================] - 0s 586us/sample - loss: 579.4557 - val_loss: 182.8302\n",
      "Epoch 322/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 606.2554 - val_loss: 153.4994\n",
      "Epoch 323/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 619.3277 - val_loss: 239.0236\n",
      "Epoch 324/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 566.1371 - val_loss: 459.4345\n",
      "Epoch 325/500\n",
      "360/360 [==============================] - 0s 392us/sample - loss: 688.2977 - val_loss: 176.1543\n",
      "Epoch 326/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 836.3529 - val_loss: 892.2590\n",
      "Epoch 327/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 952.1609 - val_loss: 180.3991\n",
      "Epoch 328/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 690.9919 - val_loss: 192.2298\n",
      "Epoch 329/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 554.3537 - val_loss: 147.3383\n",
      "Epoch 330/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 601.5774 - val_loss: 209.1517\n",
      "Epoch 331/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 639.5354 - val_loss: 553.0256\n",
      "Epoch 332/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 825.3982 - val_loss: 273.4045\n",
      "Epoch 333/500\n",
      "360/360 [==============================] - 0s 370us/sample - loss: 586.5174 - val_loss: 158.4198\n",
      "Epoch 334/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 479.0402 - val_loss: 192.2113\n",
      "Epoch 335/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 567.0857 - val_loss: 144.2628\n",
      "Epoch 336/500\n",
      "360/360 [==============================] - 0s 632us/sample - loss: 594.3112 - val_loss: 156.3707\n",
      "Epoch 337/500\n",
      "360/360 [==============================] - 0s 382us/sample - loss: 557.3577 - val_loss: 174.7400\n",
      "Epoch 338/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 508.7844 - val_loss: 149.2597\n",
      "Epoch 339/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 572.4223 - val_loss: 134.0887\n",
      "Epoch 340/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 560.2776 - val_loss: 151.2107\n",
      "Epoch 341/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 621.4965 - val_loss: 197.8912\n",
      "Epoch 342/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 501.8363 - val_loss: 123.7451\n",
      "Epoch 343/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 498.5580 - val_loss: 246.5337\n",
      "Epoch 344/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 559.7129 - val_loss: 136.4756\n",
      "Epoch 345/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 582.4428 - val_loss: 138.5397\n",
      "Epoch 346/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 535.5808 - val_loss: 118.4846\n",
      "Epoch 347/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 569.7116 - val_loss: 184.4748\n",
      "Epoch 348/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 512.5118 - val_loss: 161.5183\n",
      "Epoch 349/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 593.5477 - val_loss: 345.3735\n",
      "Epoch 350/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 663.0071 - val_loss: 165.1770\n",
      "Epoch 351/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 665.0554 - val_loss: 179.5753\n",
      "Epoch 352/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 568.5233 - val_loss: 186.7587\n",
      "Epoch 353/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 492.4957 - val_loss: 154.2559\n",
      "Epoch 354/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 608.7703 - val_loss: 425.2847\n",
      "Epoch 355/500\n",
      "360/360 [==============================] - 0s 776us/sample - loss: 731.9799 - val_loss: 137.3901\n",
      "Epoch 356/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 628.3999 - val_loss: 498.5610\n",
      "Epoch 357/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 685.7808 - val_loss: 185.6157\n",
      "Epoch 358/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 679.2872 - val_loss: 205.5572\n",
      "Epoch 359/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 622.1867 - val_loss: 156.7201\n",
      "Epoch 360/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 599.9092 - val_loss: 163.6980\n",
      "Epoch 361/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 556.0250 - val_loss: 222.5141\n",
      "Epoch 362/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 556.5506 - val_loss: 182.2189\n",
      "Epoch 363/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 683.4133 - val_loss: 175.9103\n",
      "Epoch 364/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 800.5631 - val_loss: 233.6844\n",
      "Epoch 365/500\n",
      "360/360 [==============================] - 0s 385us/sample - loss: 554.3082 - val_loss: 152.0535\n",
      "Epoch 366/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 697.1557 - val_loss: 302.6558\n",
      "Epoch 367/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 795.1386 - val_loss: 221.8018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 782.8821 - val_loss: 247.4522\n",
      "Epoch 369/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 723.7838 - val_loss: 158.9236\n",
      "Epoch 370/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 726.2919 - val_loss: 584.3392\n",
      "Epoch 371/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 969.0209 - val_loss: 232.0008\n",
      "Epoch 372/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 692.4637 - val_loss: 260.0965\n",
      "Epoch 373/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 840.6751 - val_loss: 342.2170\n",
      "Epoch 374/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 938.8752 - val_loss: 512.2950\n",
      "Epoch 375/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 943.1838 - val_loss: 832.6166\n",
      "Epoch 376/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 876.1342 - val_loss: 138.7978\n",
      "Epoch 377/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 613.9290 - val_loss: 272.6763\n",
      "Epoch 378/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 733.6185 - val_loss: 173.6733\n",
      "Epoch 379/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 620.7776 - val_loss: 362.1730\n",
      "Epoch 380/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 767.3699 - val_loss: 169.4038\n",
      "Epoch 381/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 632.3692 - val_loss: 458.6920\n",
      "Epoch 382/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 728.5278 - val_loss: 150.0838\n",
      "Epoch 383/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 534.9077 - val_loss: 203.7996\n",
      "Epoch 384/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 539.4893 - val_loss: 130.0822\n",
      "Epoch 385/500\n",
      "360/360 [==============================] - 0s 536us/sample - loss: 619.9895 - val_loss: 274.3095\n",
      "Epoch 386/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 662.1417 - val_loss: 148.0061\n",
      "Epoch 387/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 780.2321 - val_loss: 528.4684\n",
      "Epoch 388/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 637.2513 - val_loss: 160.6878\n",
      "Epoch 389/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 635.7590 - val_loss: 185.0336\n",
      "Epoch 390/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 585.1592 - val_loss: 218.0600\n",
      "Epoch 391/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 613.6712 - val_loss: 110.4144\n",
      "Epoch 392/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 661.1046 - val_loss: 276.4843\n",
      "Epoch 393/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 642.3236 - val_loss: 268.9092\n",
      "Epoch 394/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 629.6785 - val_loss: 196.7858\n",
      "Epoch 395/500\n",
      "360/360 [==============================] - 0s 530us/sample - loss: 697.4380 - val_loss: 601.1954\n",
      "Epoch 396/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 672.0817 - val_loss: 187.5300\n",
      "Epoch 397/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 645.6952 - val_loss: 309.0307\n",
      "Epoch 398/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 810.8125 - val_loss: 126.9590\n",
      "Epoch 399/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 691.3623 - val_loss: 661.5817\n",
      "Epoch 400/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 689.3831 - val_loss: 465.4759\n",
      "Epoch 401/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 721.9949 - val_loss: 239.4488\n",
      "Epoch 402/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 675.8440 - val_loss: 421.5872\n",
      "Epoch 403/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 774.5881 - val_loss: 291.7548\n",
      "Epoch 404/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 656.3342 - val_loss: 193.9403\n",
      "Epoch 405/500\n",
      "360/360 [==============================] - 0s 504us/sample - loss: 580.9011 - val_loss: 216.6658\n",
      "Epoch 406/500\n",
      "360/360 [==============================] - 0s 403us/sample - loss: 584.5507 - val_loss: 172.8160\n",
      "Epoch 407/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 572.7300 - val_loss: 172.6707\n",
      "Epoch 408/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 621.9644 - val_loss: 151.6104\n",
      "Epoch 409/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 501.4613 - val_loss: 160.4903\n",
      "Epoch 410/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 515.5223 - val_loss: 158.9353\n",
      "Epoch 411/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 668.7552 - val_loss: 382.6763\n",
      "Epoch 412/500\n",
      "360/360 [==============================] - 0s 397us/sample - loss: 738.9100 - val_loss: 219.1356\n",
      "Epoch 413/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 637.1958 - val_loss: 196.0693\n",
      "Epoch 414/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 714.7845 - val_loss: 308.5563\n",
      "Epoch 415/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 673.2600 - val_loss: 225.4915\n",
      "Epoch 416/500\n",
      "360/360 [==============================] - 0s 422us/sample - loss: 672.2158 - val_loss: 418.8913\n",
      "Epoch 417/500\n",
      "360/360 [==============================] - 0s 422us/sample - loss: 638.5810 - val_loss: 183.5550\n",
      "Epoch 418/500\n",
      "360/360 [==============================] - 0s 417us/sample - loss: 605.0654 - val_loss: 220.4803\n",
      "Epoch 419/500\n",
      "360/360 [==============================] - 0s 431us/sample - loss: 594.6532 - val_loss: 204.5805\n",
      "Epoch 420/500\n",
      "360/360 [==============================] - 0s 405us/sample - loss: 563.7711 - val_loss: 172.2772\n",
      "Epoch 421/500\n",
      "360/360 [==============================] - 0s 392us/sample - loss: 568.9849 - val_loss: 152.7550\n",
      "Epoch 422/500\n",
      "360/360 [==============================] - 0s 394us/sample - loss: 807.8764 - val_loss: 195.0890\n",
      "Epoch 423/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 762.4222 - val_loss: 622.8154\n",
      "Epoch 424/500\n",
      "360/360 [==============================] - 0s 500us/sample - loss: 716.6359 - val_loss: 193.9772\n",
      "Epoch 425/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 607.7473 - val_loss: 143.6011\n",
      "Epoch 426/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 537.2415 - val_loss: 137.8572\n",
      "Epoch 427/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 652.0912 - val_loss: 240.7924\n",
      "Epoch 428/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 649.4616 - val_loss: 362.6803\n",
      "Epoch 429/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 623.4183 - val_loss: 309.5203\n",
      "Epoch 430/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 580.2887 - val_loss: 234.8602\n",
      "Epoch 431/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 560.2794 - val_loss: 216.4816\n",
      "Epoch 432/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 441.1592 - val_loss: 141.6945\n",
      "Epoch 433/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 620.3779 - val_loss: 159.5826\n",
      "Epoch 434/500\n",
      "360/360 [==============================] - 0s 406us/sample - loss: 519.4074 - val_loss: 172.7193\n",
      "Epoch 435/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 539.9512 - val_loss: 137.8840\n",
      "Epoch 436/500\n",
      "360/360 [==============================] - 0s 355us/sample - loss: 498.3963 - val_loss: 159.6353\n",
      "Epoch 437/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 567.5721 - val_loss: 197.4254\n",
      "Epoch 438/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 632.1360 - val_loss: 171.4526\n",
      "Epoch 439/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 698.4950 - val_loss: 262.8261\n",
      "Epoch 440/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 696.1345 - val_loss: 334.2601\n",
      "Epoch 441/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 663.5949 - val_loss: 197.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 554.1118 - val_loss: 128.7026\n",
      "Epoch 443/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 564.3133 - val_loss: 141.6938\n",
      "Epoch 444/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 483.5934 - val_loss: 313.9657\n",
      "Epoch 445/500\n",
      "360/360 [==============================] - 0s 536us/sample - loss: 723.5644 - val_loss: 307.3365\n",
      "Epoch 446/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 671.6994 - val_loss: 294.6419\n",
      "Epoch 447/500\n",
      "360/360 [==============================] - 0s 370us/sample - loss: 637.5369 - val_loss: 199.1500\n",
      "Epoch 448/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 506.3197 - val_loss: 229.0992\n",
      "Epoch 449/500\n",
      "360/360 [==============================] - 0s 394us/sample - loss: 557.5989 - val_loss: 163.5242\n",
      "Epoch 450/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 548.4856 - val_loss: 215.1434\n",
      "Epoch 451/500\n",
      "360/360 [==============================] - 0s 397us/sample - loss: 591.5443 - val_loss: 177.5738\n",
      "Epoch 452/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 618.6844 - val_loss: 211.9348\n",
      "Epoch 453/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 602.0451 - val_loss: 184.9851\n",
      "Epoch 454/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 647.5896 - val_loss: 131.1457\n",
      "Epoch 455/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 662.6752 - val_loss: 185.4726\n",
      "Epoch 456/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 574.6368 - val_loss: 162.9714\n",
      "Epoch 457/500\n",
      "360/360 [==============================] - 0s 475us/sample - loss: 636.2872 - val_loss: 300.4096\n",
      "Epoch 458/500\n",
      "360/360 [==============================] - 0s 394us/sample - loss: 599.6484 - val_loss: 305.7394\n",
      "Epoch 459/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 710.5923 - val_loss: 307.0588\n",
      "Epoch 460/500\n",
      "360/360 [==============================] - 0s 406us/sample - loss: 627.7102 - val_loss: 164.2896\n",
      "Epoch 461/500\n",
      "360/360 [==============================] - 0s 381us/sample - loss: 712.0935 - val_loss: 190.4547\n",
      "Epoch 462/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 994.1343 - val_loss: 602.6427\n",
      "Epoch 463/500\n",
      "360/360 [==============================] - 0s 731us/sample - loss: 896.9602 - val_loss: 496.6088\n",
      "Epoch 464/500\n",
      "360/360 [==============================] - 0s 431us/sample - loss: 748.9498 - val_loss: 192.4146\n",
      "Epoch 465/500\n",
      "360/360 [==============================] - 0s 425us/sample - loss: 594.5839 - val_loss: 205.4427\n",
      "Epoch 466/500\n",
      "360/360 [==============================] - 0s 369us/sample - loss: 537.3144 - val_loss: 176.2497\n",
      "Epoch 467/500\n",
      "360/360 [==============================] - 0s 397us/sample - loss: 541.4798 - val_loss: 245.3733\n",
      "Epoch 468/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 693.2757 - val_loss: 132.3451\n",
      "Epoch 469/500\n",
      "360/360 [==============================] - 0s 461us/sample - loss: 799.6691 - val_loss: 431.8767\n",
      "Epoch 470/500\n",
      "360/360 [==============================] - 0s 400us/sample - loss: 568.5528 - val_loss: 150.7674\n",
      "Epoch 471/500\n",
      "360/360 [==============================] - 0s 389us/sample - loss: 534.7437 - val_loss: 364.7245\n",
      "Epoch 472/500\n",
      "360/360 [==============================] - 0s 383us/sample - loss: 714.6432 - val_loss: 335.0810\n",
      "Epoch 473/500\n",
      "360/360 [==============================] - 0s 367us/sample - loss: 826.7266 - val_loss: 605.9477\n",
      "Epoch 474/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 730.1751 - val_loss: 337.6556\n",
      "Epoch 475/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 654.1455 - val_loss: 312.6041\n",
      "Epoch 476/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 693.1166 - val_loss: 245.9442\n",
      "Epoch 477/500\n",
      "360/360 [==============================] - 0s 386us/sample - loss: 615.7453 - val_loss: 237.4662\n",
      "Epoch 478/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 508.6590 - val_loss: 176.1999\n",
      "Epoch 479/500\n",
      "360/360 [==============================] - 0s 372us/sample - loss: 511.8419 - val_loss: 149.0094\n",
      "Epoch 480/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 501.3266 - val_loss: 193.5749\n",
      "Epoch 481/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 612.9466 - val_loss: 444.4919\n",
      "Epoch 482/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 658.8820 - val_loss: 169.5860\n",
      "Epoch 483/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 723.6593 - val_loss: 299.8825\n",
      "Epoch 484/500\n",
      "360/360 [==============================] - 0s 392us/sample - loss: 668.6816 - val_loss: 223.7176\n",
      "Epoch 485/500\n",
      "360/360 [==============================] - 0s 357us/sample - loss: 642.5585 - val_loss: 576.3330\n",
      "Epoch 486/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 672.3768 - val_loss: 181.4012\n",
      "Epoch 487/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 703.7796 - val_loss: 132.8624\n",
      "Epoch 488/500\n",
      "360/360 [==============================] - 0s 355us/sample - loss: 571.0277 - val_loss: 168.0071\n",
      "Epoch 489/500\n",
      "360/360 [==============================] - 0s 375us/sample - loss: 550.8514 - val_loss: 192.3118\n",
      "Epoch 490/500\n",
      "360/360 [==============================] - 0s 371us/sample - loss: 522.8385 - val_loss: 224.5745\n",
      "Epoch 491/500\n",
      "360/360 [==============================] - 0s 356us/sample - loss: 507.7599 - val_loss: 185.3540\n",
      "Epoch 492/500\n",
      "360/360 [==============================] - 0s 353us/sample - loss: 579.6330 - val_loss: 307.4881\n",
      "Epoch 493/500\n",
      "360/360 [==============================] - 0s 650us/sample - loss: 622.6538 - val_loss: 171.4955\n",
      "Epoch 494/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 637.9935 - val_loss: 259.8810\n",
      "Epoch 495/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 750.4299 - val_loss: 425.7575\n",
      "Epoch 496/500\n",
      "360/360 [==============================] - 0s 358us/sample - loss: 582.9902 - val_loss: 175.8707\n",
      "Epoch 497/500\n",
      "360/360 [==============================] - 0s 361us/sample - loss: 628.3451 - val_loss: 216.9465\n",
      "Epoch 498/500\n",
      "360/360 [==============================] - 0s 378us/sample - loss: 590.1111 - val_loss: 250.9794\n",
      "Epoch 499/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 675.3025 - val_loss: 236.9491\n",
      "Epoch 500/500\n",
      "360/360 [==============================] - 0s 364us/sample - loss: 539.0306 - val_loss: 180.0266\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train, y=y_train, epochs=500, callbacks=[lrd, mcp], batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[399.032  ],\n",
       "       [537.7035 ],\n",
       "       [420.3618 ],\n",
       "       [500.55722],\n",
       "       [399.49942],\n",
       "       [570.7509 ],\n",
       "       [530.07654],\n",
       "       [502.85114],\n",
       "       [399.78717],\n",
       "       [466.373  ],\n",
       "       [427.22644],\n",
       "       [422.23215],\n",
       "       [421.2655 ],\n",
       "       [512.95245],\n",
       "       [425.03113],\n",
       "       [412.54654],\n",
       "       [580.9012 ],\n",
       "       [479.07724],\n",
       "       [455.5476 ],\n",
       "       [478.67792],\n",
       "       [498.167  ],\n",
       "       [505.73218],\n",
       "       [505.5702 ],\n",
       "       [647.06177],\n",
       "       [441.98007],\n",
       "       [489.58405],\n",
       "       [546.4386 ],\n",
       "       [546.94037],\n",
       "       [386.81662],\n",
       "       [315.22925],\n",
       "       [523.91266],\n",
       "       [473.64316],\n",
       "       [497.13876],\n",
       "       [301.17575],\n",
       "       [503.99197],\n",
       "       [475.25195],\n",
       "       [516.77246],\n",
       "       [429.65317],\n",
       "       [450.75378],\n",
       "       [466.09863],\n",
       "       [484.77295],\n",
       "       [456.18985],\n",
       "       [502.4903 ],\n",
       "       [493.87747],\n",
       "       [494.01367],\n",
       "       [526.5541 ],\n",
       "       [615.116  ],\n",
       "       [508.84442],\n",
       "       [294.0924 ],\n",
       "       [425.704  ],\n",
       "       [410.4007 ],\n",
       "       [476.86667],\n",
       "       [577.7289 ],\n",
       "       [613.70514],\n",
       "       [559.4788 ],\n",
       "       [485.5638 ],\n",
       "       [390.11993],\n",
       "       [460.77393],\n",
       "       [557.9669 ],\n",
       "       [488.6666 ],\n",
       "       [517.73206],\n",
       "       [382.7779 ],\n",
       "       [472.11984],\n",
       "       [477.7922 ],\n",
       "       [469.98798],\n",
       "       [541.373  ],\n",
       "       [425.19153],\n",
       "       [600.4532 ],\n",
       "       [418.3276 ],\n",
       "       [490.04034],\n",
       "       [522.0509 ],\n",
       "       [581.5031 ],\n",
       "       [617.271  ],\n",
       "       [507.5692 ],\n",
       "       [401.40646],\n",
       "       [493.0595 ],\n",
       "       [446.19   ],\n",
       "       [450.2534 ],\n",
       "       [435.1659 ],\n",
       "       [535.50806],\n",
       "       [604.92554],\n",
       "       [625.9104 ],\n",
       "       [478.51364],\n",
       "       [674.9322 ],\n",
       "       [532.6716 ],\n",
       "       [434.7502 ],\n",
       "       [503.32297],\n",
       "       [538.8458 ],\n",
       "       [320.8428 ],\n",
       "       [508.80948],\n",
       "       [539.27057],\n",
       "       [512.5829 ],\n",
       "       [376.34912],\n",
       "       [569.6031 ],\n",
       "       [480.3627 ],\n",
       "       [587.6267 ],\n",
       "       [483.7729 ],\n",
       "       [452.59622],\n",
       "       [394.77472],\n",
       "       [441.9388 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361    401.033135\n",
       "73     534.777188\n",
       "374    418.602742\n",
       "155    503.978379\n",
       "104    410.069611\n",
       "          ...    \n",
       "347    593.156401\n",
       "86     487.379306\n",
       "75     478.719357\n",
       "438    392.992256\n",
       "15     461.780742\n",
       "Name: Yearly Amount Spent, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664980629752329"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([410.4007], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418.1500810968496"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([522.0509], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532.1274491097012"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[557.60254]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sc.transform([[34, 12, 39, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(sc, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = joblib.load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[557.60254]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')\n",
    "model.predict(sc.transform([[34, 12, 39, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
